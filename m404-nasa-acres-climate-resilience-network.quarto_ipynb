{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"NASA Acres and Climate Resilience Network\"\n",
        "author: \"Jacom Almon Orser and Dr. Michael Humber\"\n",
        "format: html\n",
        "bibliography: acres-references.bib\n",
        "---\n",
        "\n",
        "# Primary Learning Objectives\n",
        "\n",
        "Technical Skills:\n",
        "\n",
        "1. Access and process satellite imagery using NASA's APPEARS platform\n",
        "2. Work with different spatial data formats and resolutions\n",
        "3. Perform raster analysis and visualization\n",
        "4. Calculate and interpret NDVI values from multispectral satellite data\n",
        "\n",
        "Analytical Skills:\n",
        "\n",
        "1. Compare vegetation health between areas affected and unaffected by saltwater intrusion\n",
        "2. Evaluate limitations and uncertainties in geospatial analysis\n",
        "\n",
        "\n",
        "## In this lesson you will:\n",
        "\n",
        "1. Understand the relationship between sealevel rise, salt water intrusion, and agricultural productivity in Maryland's coastal regions\n",
        "2. Learn to work with and analyze multiple types of geospatial data (raster datasets) using Python\n",
        "3. Interpret vegetation health patterns using satellite-derived NDVI measurements\n",
        "4. Evaluate potential future impacts of sea level rise on agricultural land\n",
        "\n",
        "This lesson will allow the learner to gain a deper understanding of the followinf concepts\n",
        "- Recognizing the economic importance of agriculture in Maryland\n",
        "- Understanding how sea level rise is impacting coastal farming\n",
        "- Identifying the role of remote sensing in monitoring environmental changes\n",
        "- Connecting local agricultural challenges to broader climate change impacts\n",
        "\n",
        "This module can help to contextualize the impact of saltwater inundation. For this module, we will identify cropland, and then, using the NOAA sea level rise estimations, we can calculate the difference in productivity using NDVI as a measure of vegetation health. A graphical time series allows us to see areas impacted by sea level rise.\n",
        "\n",
        "First, we can find the county-level statistics of harvestable acreage. We are using the Crop Data Layer (CDL) from the United States Department of Agriculture National Agriculture Statistics Service (USDA NASS)\n",
        "\n",
        "- Use API to call in the CDL dataset to map crop types.\n",
        "\n",
        "After getting familiar with the dataset, we can modify it. Because we are interested in the impact of sea level rise and the effect we can find that data from the National Oceanic and Atmospheric Administration\n",
        "\n",
        "- Access the Sea level rise (elevation dataset) to identify new areas of potential areas that are at risk of future flooding. Clip to county of interest\n",
        "- Compare the CDL with the SLR mask and without to identify the NOAA estimated loss of land.\n",
        "\n",
        "Then using Landsat create a time series for the Normalized Difference Vegetation Index (NDVI) of the masked cropland, derive insights about trends in NDVI.\n",
        "    \n",
        "- Use NDVI to create a time series looking back in time at areas that have experienced flooding to visualize the movement from productive farms to moderate quality.\n",
        "\n",
        "This all together would allow us to make a predictive analysis for Maryland in the future under the projections of sea level rise. Given the current conditions, subtracting the sea level rise inundated areas.\n",
        "\n",
        "The data story we have derived concerns sea level rise in Maryland and its impact on production levels within the state. This module can help students draw from multiple data sources and derive insights using historical and future viewing data sets.\n",
        "\n",
        "We can prompt the user to think about future impacts outside the direct sea level rise projections, allowing them to include a full picture and finally using that picture to identify economic impacts that action or inaction causes. This begs the question: What can the public do to enact changes rather than putting pressure on farmers to change?\n",
        "\n",
        "\n",
        "# Introduction\n",
        "\n",
        "Created by [NASA Acres](https://www.nasaacres.org/), this module was built to promote the research that has been done. If you want to explore more about the data collected, [explore the dashboard](https://climate.umd.edu/climate-smart-dashboard/). And provide the public with the knowledge, know-how, and ability to use and understand this data. With the help of [TOPST SCHOOL](https://ciesin-geospatial.github.io/TOPSTSCHOOL/), this data discovery process walks through each data source, identifying the limitations of research and spatial data and exploring, as George Box says, \"all models are wrong, some are useful.\"\n",
        "\n",
        "## NASA Acres\n",
        "\n",
        "[NASA Acres](https://www.nasaacres.org/) is NASA’s consortium focused on agriculture and food security in the United States.\n",
        "\n",
        "![](https://images.squarespace-cdn.com/content/v1/6376910a05a7a254908d0ee7/62ee6d54-95fc-4e05-a7a3-106a2980417d/NASA+Acres+RDE+Partner+Map.png)[^1]\n",
        "\n",
        "[^1]: Credit: NASA Acres\n",
        "\n",
        "NASA Acres brings together actors throughout the agricultural community to share methods, data, and technology to work towards a richer knowledge about past and present agricultural land use, productivity, and sustainability in the U.S. The mission is also to create a stronger agricultural technology workforce ready to tackle the challenges of climate change and global hazards to U.S. agriculture and food security.\n",
        "\n",
        "NASA Acres has defined the **Essential Agricultural Variables (EAVs)** to address this problem. These were designed by NASA Acres to define the capabilities of the top satellite data scientists and practitioners who make up NASA Acres Research, Development, and Extension partners, and the needs of decision-making-collaborators already in our network, to identify an initial set of focus.\n",
        "\n",
        "- Cropland and Crop Type Mapping\n",
        "\n",
        "- Crop and Crop Type Area Estimation\n",
        "\n",
        "This can help us determine the changes in the cropland. As things change, we can tell how much and what is actually changing because we have mapped and studied this area. The need for accurate, consistent study within these areas of agriculture is vital for describing changes as they occur.\n",
        "\n",
        "### What is Remote Sensing?\n",
        "\n",
        "Remote sensing is the action of measuring the reflectance of energy from objects. For this module we are using Landsat, a passive satellite that relies on the sun to send out energy and the sensor measures the reflectance.\n",
        "\n",
        "![](images/landsat.png)\n",
        "\n",
        "From this, we can use both the visible (red, green, blue) reflectance and the infrared light to detect objects on the ground.\n",
        "\n",
        "This is an example of a Landsat image. Compared to the aerial image, the Landsat image appears pixelated. This is because Landsat takes all the reflectances within each 30 by 30-meter square in the ground to get one value.\n",
        "\n",
        "![](images/remote_sensing.png)\n",
        "\n",
        "Generate the pull for the NDVI data. This data pull comes from The Application for Extracting and Exploring Analysis Ready Samples ([AppEEARS](https://appeears.earthdatacloud.nasa.gov/)), which offers a simple and efficient way to access data archives. We will use Landsat for this module, but a variety of datasets are available.\n",
        "\n",
        "![](images/ndvi_landsat.png)\n",
        "\n",
        "NDVI is a commonly used calculation as an indicator for the health of vegetation based on the ratio of reflectance of red to near-infrared values within the electromagnetic spectrum. If you want to learn [more](https://gisgeography.com/ndvi-normalized-difference-vegetation-index/).\n",
        "\n",
        "## WHY AGRICULTURE?\n",
        "\n",
        "According to the United States Department of Agriculture (USDA) in 2023 farming operations in Maryland (MD) were an estimated 2,000,000 acres. For grain corn in MD, in 2023, 440,000 acres were harvested. The total commercial value for all corn in the state was $355,740,000.\n",
        "\n",
        "Food is a vital resource for direct and indirect consumption. However, as salt water intrudes into agricultural land, the impacts and consequences are just beginning to be felt.\n",
        "\n",
        "As researchers, we must come to the same understanding of what is important in order to understand why we are studying agriculture.\n",
        "\n",
        "## CLIMATE SMART AGRICULTURE IN MARYLAND\n",
        "\n",
        "Why is agriculture important in Maryland and what is salt water intrusion?\n",
        "\n",
        "Researchers found that salt was intruding on coastal agricultural areas.\n",
        "\n",
        "Saltwater impacted coastal farming on a broad scale. Although there was some debate around the area lost, estimates put land losses between 8,000 to 140,000 ha of surface inundation [@Mondal2023; @taylor2020].\n",
        "\n",
        "![](https://www.mdsg.umd.edu/sites/default/files/styles/large/public/inline-images/twMedoe0cTsekaPlBkBY7cBimieC96uQTzqQjs0r8wYOv6D4Jr.png)[^2]\n",
        "\n",
        "[^2]: Photo courtesy of Jarrod Miller\n",
        "\n",
        "Researchers use satellite remote sensing to develop machine learning models built on ground-truthed data to identify salt patches in the mid-Atlantic region of the US.\n",
        "\n",
        "The U.S. Mid-Atlantic has seen higher rates of sea level rise, marshes may be especially vulnerable. “In the Chesapeake Bay, sea level rise has already contributed to the degradation of over 80,000 ha (70%) of tidal marsh” [@taylor2020]. This view can help us understand the impacts of small sea level rise on land.\n",
        "\n",
        "\n",
        "### Saltwater Intrusion\n",
        "To understand more about saltwater intrusion in Maryland, run this code and watch the video that explains the causes and effects.\n",
        "\n",
        "{{< video https://youtu.be/_J8joidx2qE >}}\n",
        "\n",
        "\n",
        "Learn more about saltwater inundation from the National Oceanic and Atmospheric Administration program titled [Coastal Farming Challenges: Flooding, Salt, and Land Loss](https://www.mdsg.umd.edu/coastal-climate-resilience/farming-flooding-salt-land-loss#:~:text=Farmers%20and%20woodlot%20owners%20in%20Maryland%20and%20Virginia%20are%20facing,under%20saltier%20or%20wetter%20conditions).\n",
        "\n",
        "Below is a simplified illustration of saltwater intrusion:\n",
        "\n",
        "![](images/Simplified_salt.png)[^3]\n",
        "\n",
        "[^3]: Courtesy of the authors\n",
        "\n",
        "\n",
        "# Data Processing Tools\n",
        "\n",
        "The primary tool we are using is Python. Python is used to take large quantities of data and help users define and derive stories from that data. The installation depends on the method you are using. For Google Colab, you must install rasterio (a substantial raster library) and import the following libraries.\n"
      ],
      "id": "067f4f0f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Use pip to install the Raster library\n",
        "# !pip install rasterio\n",
        "## importing libraries\n",
        "# Extends pandas for working with geometric/geographic data, handling spatial operations and file formats like shapefiles\n",
        "import geopandas as gpd\n",
        "\n",
        "# Handles reading, writing, and processing of geospatial raster data (like satellite imagery or elevation data)\n",
        "import rasterio\n",
        "\n",
        "#Using Amazon S3 Buckets for data download\n",
        "from rasterio.session import AWSSession\n",
        "import boto3\n",
        "\n",
        "# Fundamental package for scientific computing in Python, provides support for large multi-dimensional arrays and matrices\n",
        "import numpy as np  # Note: This is imported twice in your list\n",
        "\n",
        "# Data manipulation and analysis library, particularly good for structured data in DataFrames\n",
        "import pandas as pd\n",
        "\n",
        "# Plotting library for creating static, animated, and interactive visualizations\n",
        "import matplotlib.pyplot as plt  # Note: This is imported twice in your list\n",
        "\n",
        "# Library for making HTTP requests to web services and APIs\n",
        "import requests\n",
        "\n",
        "#import json package\n",
        "import json\n",
        "\n",
        "# API for parsing and creating XML data\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "# Handles binary I/O objects\n",
        "from io import BytesIO\n",
        "\n",
        "# Provides functions for interacting with the operating system\n",
        "import os\n",
        "\n",
        "# Specific tools for transforming and reprojecting raster data\n",
        "from rasterio.warp import calculate_default_transform, reproject, Resampling, transform_bounds\n",
        "\n",
        "# Basic date and time types, useful for handling temporal data\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Creates interactive web maps\n",
        "import folium\n",
        "\n",
        "#  Adds raster layers (e.g., satellite images) to Folium maps\n",
        "from folium import raster_layers\n",
        "\n",
        "# Display graphical interfaces\n",
        "from IPython.display import display"
      ],
      "id": "8ba87eb8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The base data that we are going to use for this module is Landsat 30 by 30 meter, 16 day highest quality NDVI value. To gather this data you must have a [Earth Data](https://urs.earthdata.nasa.gov/) login.\n",
        "\n",
        "## INTRODUCTORY CODE\n",
        "\n",
        "### Accessing Data\n",
        "\n",
        "NASA Earth data requires a data pull request, this takes time to 'order', we can run this now to give the program time to gather the data we are requesting. **This code chunk is used for local downloads if you have not yet downloaded data**:\n"
      ],
      "id": "6760776f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false \n",
        "\n",
        "\n",
        "## NASA Earth Data username and password\n",
        "USERNAME = \"jfmartinez4\" ## ENTER HERE\n",
        "PASSWORD = \"Cafeconpan12!\" ## ENTER HERE\n",
        "\n",
        "## The submit the Landsat tiles, we have provided you with the geojson file of Talbot County.\n",
        "## If you wish to use another county, download, and path to the other county geojson file\n",
        "county_path = 'data/Talbot_County.geojson' # Path to county"
      ],
      "id": "45a66f43",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "\n",
        "\n",
        "## NASA Earth Data username and password\n",
        "# USERNAME = \"USERNAME\" ## ENTER HERE\n",
        "# PASSWORD = \"PASSWORD\" ## ENTER HERE\n",
        "\n",
        "## The submit the Landsat tiles, we have provided you with the geojson file of Talbot County.\n",
        "## If you wish to use another county, download, and path to the other county geojson file\n",
        "county_path = 'data/Talbot_County.geojson' # Path to county"
      ],
      "id": "b1322738",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Conversion to geopandas data frame\n",
        "county_data =  gpd.read_file(county_path)\n",
        " # Reproject the county_data to landsat\n",
        "county_reprojected = county_data.to_crs('EPSG:4326')\n",
        "\n",
        "year = 2018 # Year of interest"
      ],
      "id": "c475468d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Creating an APPEEARS token\n",
        "\n",
        "Accessing data directly from the NASA Earthdata Cloud APPEEARS website requires to make a request with your Earthdata Username and Password. This request generates a **token**:"
      ],
      "id": "726e6d63"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Get the token from your Earth Data account\n",
        "token = requests.post('https://appeears.earthdatacloud.nasa.gov/api/login',auth=(USERNAME, PASSWORD)).json()['token']"
      ],
      "id": "704cd8d1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With the token, you can create an APPEEARS task that requests a data package. An email is sent to you with confirmation and updates on your request.  NOTE: This requrest may take a few hours to be filled.\n"
      ],
      "id": "c2b1e56a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "\n",
        "# task = {'task_type': 'area',\n",
        "#           'task_name': 'Talbot_County',\n",
        "#           'params': {\n",
        "#                     'dates': [{'startDate':  f'06-01-{year}' , 'endDate': f'09-30-{year}'}],# Set the start and end dates for summer sections\n",
        "#                     'layers': [{'layer': 'SR_B4', 'product':'L08.002'},\n",
        "#                                {'layer': 'SR_B5', 'product':'L08.002'}], # Data of interest is the NDVI values\n",
        "#                     'geo': { #The geo field should contain the geoJSON, currently it is in a set\n",
        "#                         'type': 'FeatureCollection',\n",
        "#                         'features': [{\n",
        "#                             'type': 'Feature',\n",
        "#                             'properties': {},\n",
        "#                             'geometry': county_reprojected.geometry.iloc[0].__geo_interface__ #Extracting the geometry from the GeoPandas DataFrame as a GeoJSON-compatible dictionary\n",
        "#                         }]\n",
        "#                     },\n",
        "#                     \"output\": {\"format\": {\"type\": \"geotiff\"},\n",
        "#                               \"projection\": \"native\"}}}\n",
        "\n",
        "# task_id = requests.post('https://appeears.earthdatacloud.nasa.gov/api/task',json=task,headers={'Authorization': f'Bearer {token}'}).json()"
      ],
      "id": "0dc75bb6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You should receive an email from APPEEARS that says the task has started. \n"
      ],
      "id": "007f8c3b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| echo: false\n",
        "\n",
        "# I've created a request with ID for this session: \n",
        "task_id = {}\n",
        "\t\n",
        "task_id['task_id'] = 'f7f2bc1b-46bc-4d5d-9421-74e165b576ed'\n",
        "task_id['status'] = 'done'"
      ],
      "id": "c2f189e7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Working with Rasters\n",
        "\n",
        "### Reading Raster Data\n",
        "\n",
        "There are two ways to display information: vectors (points, lines, polygons) or rasters. Rasters are continuous sheets that are layered across a space; they are made up of pixels. Each pixel represents the ground beneath it. For example, if a raster pixel is 30 by 30 meters, that means a single pixel represents 30 by 30 meters on the ground.\n"
      ],
      "id": "e8c3120e"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fips = \"24041\" # County code for all US counties, remember we called this in the first code chunk when we used the geojson to gather Landsat NDVI images\n",
        "year = 2018 # Year of interest\n",
        "\n",
        "# The CDL (crop data layer) is the authoritative data layer for the US crops\n",
        "base_url = \"https://nassgeodata.gmu.edu/axis2/services/CDLService/GetCDLFile\"\n",
        "\n",
        "# Pulling the data from the online source using the requests library allows us to access the data without needing to download the dataset\n",
        "response = requests.get(f\"{base_url}?year={year}&fips={fips}\")\n",
        "print(response.content)\n",
        "root = ET.fromstring(response.content)\n",
        "tif_url = root.find('.//returnURL').text\n",
        "cdl_data = rasterio.open(tif_url)\n",
        "cdl_meta = cdl_data.meta\n",
        "data = cdl_data.read(1)"
      ],
      "id": "74e526ae",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Displaying Raster Data\n",
        "MISSING TEXT\n"
      ],
      "id": "1b09ddf3"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bounds = transform_bounds(cdl_data.crs, 'EPSG:4326', *cdl_data.bounds)\n",
        "\n",
        "# Calculate the center of the image for the map\n",
        "center_lat = (bounds[1] + bounds[3]) / 2\n",
        "center_lon = (bounds[0] + bounds[2]) / 2\n",
        "\n",
        "# Create a base map centered on the image\n",
        "m = folium.Map(location=[center_lat, center_lon], zoom_start=10)\n",
        "\n",
        "# Add the raster layer to the map\n",
        "img = folium.raster_layers.ImageOverlay(\n",
        "    data,\n",
        "    bounds=[[bounds[1], bounds[0]], [bounds[3], bounds[2]]],\n",
        "\n",
        ")\n",
        "img.add_to(m)\n",
        "\n",
        "# Add the colormap to the map\n",
        "\n",
        "# Add layer control\n",
        "folium.LayerControl().add_to(m)\n",
        "display(m)"
      ],
      "id": "57226747",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        " Zoom around in on the map. Look at the raster structure, the squares stacked next to each other, representing an area on the ground.\n",
        "\n",
        "### Spatially Project Raster Data\n",
        "\n",
        "When working with geographic data, we have to begin by knowing that all of our data is in the right space on the globe. We begin with a function for reprojecting rasters. This is one of the keys when working with spatial data: ensuring that all of the data is based on the same spatial reference.\n",
        "\n",
        "Reprojecting requires a resampling method; for this, we use the nearest neighbor's resampling.\n",
        "\n",
        "![](images/nearest_neighbor.png)\n"
      ],
      "id": "8b62d404"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def reproject_raster(src_dataset, src_crs, src_transform, dst_crs):\n",
        "    # Convert the destination CRS string into a CRS object that rasterio can use\n",
        "    # For example, 'EPSG:4326' becomes a python coordinate object\n",
        "    dst_crs = rasterio.crs.CRS.from_string(dst_crs)\n",
        "\n",
        "    # Calculate the new dimensions and transformation matrix for the output raster\n",
        "    # This ensures the whole image fits in the new coordinate system\n",
        "    dst_transform, dst_width, dst_height = calculate_default_transform(\n",
        "        src_crs,                    # Current coordinate system\n",
        "        dst_crs,                    # Target coordinate system\n",
        "        src_dataset.width,          # Current image width\n",
        "        src_dataset.height,         # Current image height\n",
        "        *src_dataset.bounds         # The geographical bounds of the image\n",
        "    )\n",
        "\n",
        "    # Copy the metadata from the source dataset\n",
        "    # This includes things like data type, number of bands, etc.\n",
        "    dst_kwargs = src_dataset.meta.copy()\n",
        "\n",
        "    # Update the metadata with the new CRS, transform, width, and height\n",
        "    dst_kwargs.update({\n",
        "        'crs': dst_crs,\n",
        "        'transform': dst_transform,\n",
        "        'width': dst_width,\n",
        "        'height': dst_height\n",
        "    })\n",
        "\n",
        "    # Create an empty array to store the reprojected data\n",
        "    # Shape is (number of bands, new height, new width)\n",
        "    dst_data = np.zeros((src_dataset.count, dst_height, dst_width),\n",
        "                       dtype=src_dataset.dtypes[0])\n",
        "    reproject(\n",
        "        source=rasterio.band(src_dataset,1),\n",
        "        destination=dst_data,             # Where to store the result\n",
        "        src_transform=src_transform,           # Current transformation\n",
        "        src_crs=src_crs,                      # Current coordinate system\n",
        "        dst_transform=dst_transform,           # New transformation\n",
        "        dst_crs=dst_crs,                      # New coordinate system\n",
        "        resampling=Resampling.nearest         # Use nearest neighbor resampling\n",
        "    )\n",
        "\n",
        "    # Return both the reprojected data and the updated metadata\n",
        "    return dst_data, dst_kwargs"
      ],
      "id": "abcd292f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Access data with API\n",
        "\n",
        "To understand the nature of Maryland agriculture we can begin by using the CDL. This raster dataset comes at a 30-meter spatial resolution. We can access this data through their API. The current configuration allows data to be pulled at the county level.\n",
        "\n",
        "[COUNTY LEVEL CDL FOR FIPS](https://nassgeodata.gmu.edu/axis2/services/CDLService/GetCDLFile)\n",
        "\n",
        "This view provides insight into the common commodities that are grown in Maryland in the desired year.\n"
      ],
      "id": "e35e04f1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "cdl_reprojected, cdl_meta_reprojected = reproject_raster(cdl_data, cdl_meta['crs'], cdl_meta['transform'], 'EPSG:4326')"
      ],
      "id": "cda5ce1c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The eastern seaboard has seen changes in the sea level along with increased flooding and the decrease in the predictability of water flow from rivers. This data comes from [NOAA](https://coast.noaa.gov/data/digitalcoast/pdf/slr-inundation-methods.pdf), this raster is the projection of inundated areas by the year 2050. Data access can be found [here](https://coast.noaa.gov/slrdata/Depth_Rasters/MD/index.html).\n",
        "\n",
        "Amazon AWS S3 Bucket - Cloud Access to the data:"
      ],
      "id": "32343299"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# S3 path to the sea level rise TIFF file\n",
        "slr_s3_url = \"https://tops-school.s3.us-west-2.amazonaws.com/climate-agriculture-module/MD_East_slr_depth_3_5ft.tif\"\n",
        "\n",
        "# Convert S3 URL to GDAL-compatible format\n",
        "slr_s3_gdal_path = \"/vsicurl/\" + slr_s3_url  # Allows rasterio to read from S3 directly\n",
        "\n",
        "# Open the raster from S3, then reproject\n",
        "with rasterio.open(slr_s3_gdal_path) as slr_raster:\n",
        "    slr_meta = slr_raster.meta.copy()\n",
        "    slr_meta['nodata'] = 0  # Set nodata value\n",
        "\n",
        "    # Reproject\n",
        "    slr_reprojected, slr_meta_reprojected = reproject_raster(\n",
        "        slr_raster,\n",
        "        slr_meta['crs'],\n",
        "        slr_meta['transform'],\n",
        "        'EPSG:4326'\n",
        "    )"
      ],
      "id": "d026919b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If you've downloaded the data locally:"
      ],
      "id": "42ae55bc"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# # Path to the stored sea level rise tif file\n",
        "# slr_path = 'data/MD_East_slr_depth_3_5ft.tif'\n",
        "\n",
        "# # This allows us to open the raster file, then reproject and close the original file so we are not storing duplicates of the raster\n",
        "# with rasterio.open(slr_path) as slr_raster:\n",
        "#     slr_meta = slr_raster.meta.copy()\n",
        "#     slr_meta['nodata'] = 0\n",
        "\n",
        "#     # Reproject\n",
        "#     slr_reprojected, slr_meta_reprojected = reproject_raster(\n",
        "#         slr_raster,\n",
        "#         slr_meta['crs'],\n",
        "#         slr_meta['transform'],\n",
        "#         'EPSG:4326')"
      ],
      "id": "f3c66928",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Working with NASA APPEEARS Data\n",
        "\n",
        "You should have received an email from APPEEARS letting you know your task has completed. If you have not received this, go to the APPEEARS website to view the progress by clicking on the explore tab and viewing the TALBOT_COUNTY request.\n"
      ],
      "id": "496e4c76"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## NASA hosts their Landsat data in their program called APPEEARS\n",
        "# To access the data you must probe it from cold storage, that was the initial code we ran\n",
        "# If you wish to learn more, visit the API documentation from appeears\n",
        "def doy_2_date(day_of_year_str): # This function changes the DOY value to a more easily readable format (from Julian day of the year to date based on month day year)\n",
        "              year = int(day_of_year_str[:4]) # year string to integer\n",
        "              day_of_year = int(day_of_year_str[4:]) # Julian day string to integer\n",
        "              start_date = datetime(year, 1, 1) # using datetime to change year to first day first month of the year of interest\n",
        "              target_date = start_date + timedelta(days=day_of_year - 1) # add the DOY of acquisition to the year\n",
        "              return target_date.strftime('%m-%d-%Y') ## return proper formatting"
      ],
      "id": "c661c97c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The token and Task ID created previously for APPEEARS can be used here to create a 'bundle' which carries multiple datasets from APPEEARS"
      ],
      "id": "b1d82c11"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "bundle = requests.get(f'https://appeears.earthdatacloud.nasa.gov/api/bundle/{task_id[\"task_id\"]}',headers={'Authorization': f'Bearer {token}'}).json()\n",
        "QA_data = {}\n",
        "data = {} # Create an empty dictionary to collect the data from appeears"
      ],
      "id": "c9a04d43",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for file in bundle['files']: # loops through each Landsat tile that we called.\n",
        "    file_id = file['file_id'] # store the name of the tile\n",
        "    if '_doy' in file['file_name']: \n",
        "        # doy is the day of the year, ordering the dictionary by doy allows for easier access later\n",
        "        # This allows us to get just the files of interest. We only want the\n",
        "        if \"SR_B4\" in file['file_name'] or \"SR_B5\" in file['file_name'] or \"QA_PIXEL_C\" in file['file_name']:\n",
        "            datesy = file['file_name'].split('_doy')[1][:7] # seperation of doy values\n",
        "            doy = doy_2_date(datesy) # calling the function (from Julian day (001 is the first day of the year, 365 is the last day of the year) to mm-dd-yyyy\n",
        "            band = file['file_name'].split('/L08.002_')[1][:5]\n",
        "            # access the NDVI data via request library\n",
        "            file_download = requests.get('https://appeears.earthdatacloud.nasa.gov/api/bundle/{0}/{1}'.format(task_id['task_id'], file_id), headers={'Authorization': 'Bearer {0}'.format(token)}, allow_redirects=True, stream=True)\n",
        "            # Get the status of the file\n",
        "            file_download.raise_for_status()\n",
        "            # This error warning allows for continuation even if there is an error\n",
        "            if not file_download.content:\n",
        "                print(f\"Warning: Empty file downloaded for {file['file_name']}\") # print warning message if there is an error, continue to next data set otherwise\n",
        "                continue\n",
        "            file_content = BytesIO(file_download.content) # format the downloaded content\n",
        "            with rasterio.open(file_content) as src_initial: # open the accessed raster\n",
        "                src = src_initial.read(1, masked=True) # read in the layer data\n",
        "                src_meta = src_initial.meta # access the metadata\n",
        "                dst_crs = 'EPSG:4326' # define the crs\n",
        "                transform, width, height = calculate_default_transform(\n",
        "                    src_meta['crs'], dst_crs, src.shape[1], src.shape[0], *src_initial.bounds)\n",
        "                kwargs = src_meta.copy()\n",
        "                # collect the current meta data information\n",
        "                kwargs.update({\n",
        "                    'crs': dst_crs,\n",
        "                    'transform': transform,\n",
        "                    'width': width,\n",
        "                    'height': height\n",
        "                })\n",
        "\n",
        "                dst = np.zeros((height, width), dtype=src_meta['dtype'])\n",
        "                # Begin the reprojection process based on earlier defined projections of interest\n",
        "                reproject(\n",
        "                    source=src,\n",
        "                    destination=dst,\n",
        "                    src_transform=src_meta['transform'],\n",
        "                    src_crs=src_meta['crs'],\n",
        "                    dst_transform=transform,\n",
        "                    dst_crs=dst_crs,\n",
        "                    resampling=Resampling.nearest)\n",
        "\n",
        "                # update the data (if no data set to 0)\n",
        "                kwargs.update({'nodata': 0})\n",
        "                # name the data\n",
        "                key = f'{band}'\n",
        "                if key not in data:\n",
        "                    # if first dataset, append the metadata to the entire dictionary\n",
        "                    data[key] = {'data': [], 'meta': kwargs, 'doy': []}\n",
        "                # stack the data and data\n",
        "                data[key]['data'].append(dst)\n",
        "                data[key]['doy'].append(doy)\n",
        "        else:\n",
        "          continue\n",
        "\n",
        "    else:\n",
        "      continue\n"
      ],
      "id": "c8c6a5d3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extract some of the data into variables"
      ],
      "id": "1df1207b"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# name the stacked data, day, and metadata to be referenced later\n",
        "nir = np.stack(data['SR_B5']['data']) / 1000\n",
        "red = np.stack(data['SR_B4']['data']) / 1000\n",
        "qa_flags = np.stack(data['QA_PI']['data'])\n",
        "day = np.stack(data['SR_B5']['doy'])\n",
        "meta_nir = data['SR_B5']['meta']\n",
        "meta_red = data['SR_B4']['meta']\n",
        "\n",
        "#handing 0 and NaN values when dividing\n",
        "denominator = nir + red\n",
        "denominator = np.where(denominator == 0, np.nan, denominator)  # Avoid division by zero\n",
        "ndvi = (nir - red) / denominator  # Compute NDVI safely\n",
        "ndvi = np.nan_to_num(ndvi, nan=0)\n"
      ],
      "id": "88fdd606",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have an NDVI dataset for each date, we have to filter out the cloudy or otherwise poor-quality NDVI values.\n",
        "\n",
        "![](images/PixelQA.png)\n"
      ],
      "id": "b0c620af"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "qa_flags_to_mask = [21824, 21890, 21952, 22018, 22146, 22208] ## These are the values that indicate the higher quality of pixel\n",
        "masked_ndvi = np.where(np.isin(qa_flags, qa_flags_to_mask), np.nan, ndvi) # filter the NDVI array"
      ],
      "id": "366d3c4b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "## This function resamples the data to the same\n",
        "# Because the NDVI is 30 by 30-meters, the CDL data is at 30 by 30-meter resolution, and the SLR is less than 10 by 10-meter resolution\n",
        "# Resampling to the same spatial scale allows for analysis on the same spatial scale\n",
        "def resample_data(data, data_meta, to_reproject, method):\n",
        "    # collect the metadata from the CDL dataset\n",
        "    resampled_data = np.zeros(\n",
        "        (data.shape[0], to_reproject['height'], to_reproject['width']),\n",
        "        dtype=data.dtype\n",
        "    )\n",
        "    # collect the metadata from the target dataset\n",
        "    for i in range(data.shape[0]): # Because the NDVI stack has multiple dates, we have to loop through the stacked data\n",
        "        reproject(\n",
        "            source=data[i],\n",
        "            destination=resampled_data[i],\n",
        "            src_transform=data_meta['transform'],\n",
        "            src_crs=data_meta['crs'],\n",
        "            dst_transform=to_reproject['transform'],\n",
        "            dst_crs=to_reproject['crs'],\n",
        "            resampling=method # method of resampling - either nearest neightbor or bilinear (average of 4 closest neighbors)\n",
        "        )\n",
        "    # update the target dataset to the CDL dataset height and width\n",
        "    updated_meta = data_meta.copy()\n",
        "    updated_meta.update({\n",
        "        'transform': to_reproject['transform'],\n",
        "        'width': to_reproject['width'],\n",
        "        'height': to_reproject['height'],\n",
        "        'crs': to_reproject['crs']\n",
        "    })\n",
        "\n",
        "    return resampled_data, updated_meta\n",
        "\n",
        "cdl_resampled, cdl_resampled_meta = resample_data(cdl_reprojected, cdl_meta_reprojected, meta_red, Resampling.nearest)\n",
        "slr_resampled, slr_resampled_meta = resample_data(slr_reprojected, slr_meta_reprojected, meta_red, Resampling.bilinear)\n",
        "\n",
        "# print out the dataset shapes to see how the transformation has changed the resolution of the data\n",
        "print(\"NDVI shape:\", ndvi.shape)\n",
        "\n",
        "print(\"Original CDL shape:\", cdl_reprojected.shape)\n",
        "print('Resampled CDL:', cdl_resampled.shape)\n",
        "\n",
        "print(\"Original SLR shape:\", slr_reprojected.shape)\n",
        "print(\"Resampled SLR shape:\", slr_resampled.shape)"
      ],
      "id": "55f66225",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This code places both rasters on the same map. We first select only corn (where the CDL value is equal to 1). Look on the CDL website if you are interested in other land classes.\n"
      ],
      "id": "4d4022f0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create corn and water masks\n",
        "corn_mask = (cdl_resampled[0, :, :] == 1).astype(np.uint8)  # Corn is labeled as 1 in CDL\n",
        "SLR_MASK = (slr_resampled[0, :, :] <= 10).astype(np.uint8)  # Areas predicted to be underwater\n",
        "\n",
        "# Visualize the masks\n",
        "fig, ax = plt.subplots(figsize=(15, 5))\n",
        "ax.imshow(corn_mask, cmap='Greens', alpha=0.5, label=\"Corn Fields\")\n",
        "ax.imshow(SLR_MASK, cmap='Blues', alpha=0.5, label=\"Flooded Areas\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "id": "951e3517",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Calculate the area of overlap between the corn and water masks.\n",
        "overlap_mask = np.logical_and(corn_mask, SLR_MASK)\n",
        "\n",
        "# Get the resolution of the raster data (assuming both are the same)\n",
        "resolution = meta_red['transform'][0]  # Assuming the transform is consistent across all rasters\n",
        "# Calculate the area of each pixel in acres (1 acre = 43560 sq ft)\n",
        "pixel_area_acres = (30 * 3.28084)**2 / 43560 # convert from 30 meters to acres\n",
        "\n",
        "# Calculate the total impacted area\n",
        "impacted_acres = np.sum(overlap_mask) * pixel_area_acres\n",
        "\n",
        "print(f\"Acres impacted by flooding in corn fields: {impacted_acres:.2f}\")\n",
        "\n",
        "# Calculate the area of corn based on the corn mask.\n",
        "corn_area_acres = np.sum(corn_mask) * pixel_area_acres\n",
        "print(f\"Total acres of corn: {corn_area_acres:.2f}\")"
      ],
      "id": "ce864f36",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "What can we tell from the changes in corn acreage and the amount below\n",
        "\n",
        "#### Graphically view the changes in NDVI.\n"
      ],
      "id": "34302db0"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Ensure masks match NDVI shape (time, height, width)\n",
        "corn_below_water_mask = np.expand_dims(corn_mask & SLR_MASK, axis=0)  # Add time axis\n",
        "corn_below_water_mask = np.broadcast_to(corn_below_water_mask, masked_ndvi.shape)  # Match NDVI shape\n",
        "\n",
        "corn_above_water_mask = np.expand_dims(corn_mask & ~SLR_MASK, axis=0)  # Add time axis\n",
        "corn_above_water_mask = np.broadcast_to(corn_above_water_mask, masked_ndvi.shape)  # Match NDVI shape\n",
        "\n",
        "# Extract NDVI values using masks\n",
        "masked_ndvi_below_water = np.where(corn_below_water_mask, masked_ndvi, np.nan)\n",
        "masked_ndvi_above_water = np.where(corn_above_water_mask, masked_ndvi, np.nan)"
      ],
      "id": "f1008ba0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Safe computation of NDVI statistics\n",
        "def safe_stat(ndvi_array, func):\n",
        "    valid_values = np.where(~np.isnan(ndvi_array), ndvi_array, np.nan)\n",
        "    return func(valid_values, axis=(1, 2)) if np.any(~np.isnan(valid_values)) else 0\n",
        "\n",
        "ndvi_analysis = {\n",
        "    'corn_below_water': {\n",
        "        'mask': corn_below_water_mask,\n",
        "        'ndvi': np.nan_to_num(masked_ndvi_below_water, nan=0),  # Replace NaN with 0\n",
        "        'mean': np.nan_to_num(safe_stat(masked_ndvi_below_water, np.nanmean), nan=0),\n",
        "        'min': np.nan_to_num(safe_stat(masked_ndvi_below_water, np.nanmin), nan=0),\n",
        "        'max': np.nan_to_num(safe_stat(masked_ndvi_below_water, np.nanmax), nan=0),\n",
        "    },\n",
        "    'corn_above_water': {\n",
        "        'mask': corn_above_water_mask,\n",
        "        'ndvi': np.nan_to_num(masked_ndvi_above_water, nan=0),  # Replace NaN with 0\n",
        "        'mean': np.nan_to_num(safe_stat(masked_ndvi_above_water, np.nanmean), nan=0),\n",
        "        'min': np.nan_to_num(safe_stat(masked_ndvi_above_water, np.nanmin), nan=0),\n",
        "        'max': np.nan_to_num(safe_stat(masked_ndvi_above_water, np.nanmax), nan=0),\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Mean NDVI Plot\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(day[:len(ndvi_analysis['corn_above_water']['mean'])], ndvi_analysis['corn_above_water']['mean'], \n",
        "         label='Corn Above Water', color='green', marker='o')\n",
        "plt.plot(day[:len(ndvi_analysis['corn_below_water']['mean'])], ndvi_analysis['corn_below_water']['mean'], \n",
        "         label='Corn Below Water', color='blue', marker='o')\n",
        "plt.title('Mean NDVI')\n",
        "plt.xlabel('Days')\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylabel('NDVI')\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle=\"--\")\n",
        "\n",
        "# Maximum NDVI Plot\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(day[:len(ndvi_analysis['corn_above_water']['max'])], ndvi_analysis['corn_above_water']['max'], \n",
        "         label='Corn Above Water', color='green', linestyle='dashed', marker='s')\n",
        "plt.plot(day[:len(ndvi_analysis['corn_below_water']['max'])], ndvi_analysis['corn_below_water']['max'], \n",
        "         label='Corn Below Water', color='blue', linestyle='dashed', marker='s')\n",
        "plt.title('Maximum NDVI')\n",
        "plt.xlabel('Days')\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylabel('NDVI')\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle=\"--\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print the NDVI analysis summary\n",
        "for condition in ['corn_below_water', 'corn_above_water']:\n",
        "    print(f\"\\n{condition.replace('_', ' ').title()} Corn Analysis per tile:\")\n",
        "    for stat in ['mean', 'max']:\n",
        "        print(f\"{stat.capitalize()} NDVI: {ndvi_analysis[condition][stat]}\")"
      ],
      "id": "0f0ac638",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can see that it is currently in trouble because the NDVI values are already lower, but we also know the number of acres impacted. What are the estimations for the loss of land? Building on that, what other areas beyond these calculations might be impacted as the sea rises?\n",
        "\n",
        "We can see that the corn predicted to be below water in 2050 is already showing signs of decreased NDVI values. As the sea level continues to rise and salinization impacts farmers, what are the future conditions for corn growing in Maryland? What are the estimated impacts? What can we do?\n"
      ],
      "id": "80f390a1"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Final Analysis and Reflection Section\n",
        "\n",
        "# Cropland and Crop Type Mapping Insights\n",
        "cropland_impact = {\n",
        "    'total_corn_acres': corn_area_acres,\n",
        "    'projected_flooded_acres': impacted_acres,\n",
        "    'percent_at_risk': (impacted_acres / corn_area_acres) * 100\n",
        "}\n",
        "\n",
        "# Crop Area Estimation Insights\n",
        "ndvi_trend_analysis = {\n",
        "    'below_water_ndvi_mean': np.mean(ndvi_analysis['corn_below_water']['mean']),\n",
        "    'above_water_ndvi_mean': np.mean(ndvi_analysis['corn_above_water']['mean']),\n",
        "    'productivity_difference': np.mean(ndvi_analysis['corn_above_water']['mean']) - np.mean(ndvi_analysis['corn_below_water']['mean'])\n",
        "}\n",
        "\n",
        "# Print Narrative Report\n",
        "print(\"\\n--- NASA Acres Essential Agricultural Variables (EAV) Analysis ---\")\n",
        "print(f\"Total Corn Acreage: {cropland_impact['total_corn_acres']:.2f} acres\")\n",
        "print(f\"Projected Flood Impact: {cropland_impact['projected_flooded_acres']:.2f} acres\")\n",
        "print(f\"Percentage of Corn Land at Risk: {cropland_impact['percent_at_risk']:.2f}%\")\n",
        "print(f\"\\nNDVI Productivity Assessment:\")\n",
        "print(f\"  Corn Above Water NDVI: {ndvi_trend_analysis['above_water_ndvi_mean']:.4f}\")\n",
        "print(f\"  Corn Below Water NDVI: {ndvi_trend_analysis['below_water_ndvi_mean']:.4f}\")\n",
        "print(f\"  Productivity Difference: {ndvi_trend_analysis['productivity_difference']:.4f}\")\n",
        "\n",
        "# Reflection on Broader Implications\n",
        "print(\"\\nReflection:\")\n",
        "print(\"This analysis demonstrates the critical importance of:\")\n",
        "print(\"1. Continuous monitoring of agricultural lands\")\n",
        "print(\"2. Understanding climate change impacts on crop productivity\")\n",
        "print(\"3. Developing adaptive strategies for coastal agricultural communities\")"
      ],
      "id": "9e2fceca",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Knowledge Check\n",
        "\n",
        "Test your knowledge from this module.\n",
        "\n",
        "- What are the insights that we can derive from this module?\n",
        "- What are the current impacts of land being close to the water?\n",
        "- What is the potential loss of productive land?\n",
        "- Where could there be errors given the sampling methods?\n",
        "\n",
        "This is where mapping and monitoring the changes in our farmland is crucial. We can identify, monitor, and track changes as they arise. We can apply this view to a historical view using earlier imagery or later imagery to track the newest updates, even applying models to highlight potential future views.\n",
        "\n",
        "\n",
        "## Printing and Sharing Results\n",
        "\n",
        "If you want to download the tifs you created, you can do so here.\n"
      ],
      "id": "2fda67e7"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "\n",
        "\n",
        "SLR_output_tif_path = '' # Replace with your desired path\n",
        "slr_masked_int = SLR_MASK.astype(rasterio.uint8)\n",
        "\n",
        "\n",
        "with rasterio.open(\n",
        "    SLR_output_tif_path,\n",
        "    'w',\n",
        "    driver='GTiff',\n",
        "    height=slr_resampled_meta['height'],\n",
        "    width=slr_resampled_meta['width'],\n",
        "    count=1,  # Number of bands in the output GeoTIFF\n",
        "    dtype=rasterio.uint8,\n",
        "    crs=slr_resampled_meta['crs'],\n",
        "    transform=slr_resampled_meta['transform'],\n",
        "    nodata=0 # Set nodata value if necessary\n",
        ") as dst:\n",
        "    dst.write(slr_masked_int, 1)\n",
        "\n",
        "print(f\"Masked SLR saved to: {SLR_output_tif_path}\")"
      ],
      "id": "993f366b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "#| eval: false\n",
        "\n",
        "\n",
        "corn_maskoutput_tif_path = '' # Replace with your desired path\n",
        "corn_mask_int = corn_mask.astype(rasterio.uint8)\n",
        "\n",
        "\n",
        "with rasterio.open(\n",
        "    corn_maskoutput_tif_path,\n",
        "    'w',\n",
        "    driver='GTiff',\n",
        "    height=cdl_resampled_meta['height'],\n",
        "    width=cdl_resampled_meta['width'],\n",
        "    count=1,  # Number of bands in the output GeoTIFF\n",
        "    dtype=rasterio.uint8,\n",
        "    crs=cdl_resampled_meta['crs'],\n",
        "    transform=cdl_resampled_meta['transform'],\n",
        "    nodata=0 # Set nodata value if necessary\n",
        ") as dst:\n",
        "    dst.write(corn_mask_int, 1)\n",
        "\n",
        "print(f\"Masked SLR saved to: {corn_maskoutput_tif_path}\")"
      ],
      "id": "70324707",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/christinadeo/Library/Python/3.9/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}